{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauriciomau0/ML-Based-Performance-Monitoring-Approach-for-Athlete-Performance-Attenuation-Prediction/blob/main/Test_ML_Paper_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a62e71f8",
      "metadata": {
        "id": "a62e71f8"
      },
      "source": [
        "# Initial Data Loading and Feature Dropping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b91f21",
      "metadata": {
        "id": "c1b91f21"
      },
      "source": [
        "The code reads data from an Excel file (pd.read_excel) and displays the first few rows (data.head()), which are standard initial steps in preparing data for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eb7cd03",
      "metadata": {
        "id": "4eb7cd03"
      },
      "source": [
        "## Importing the appropriate packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b46b3f",
      "metadata": {
        "id": "b0b46b3f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b15693",
      "metadata": {
        "id": "17b15693"
      },
      "source": [
        "## Loading our data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(\"/content/Data_PhD.xlsx\")\n",
        "print(type(data))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ZhqXN6l9v_fk",
        "collapsed": true
      },
      "id": "ZhqXN6l9v_fk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "zquYt37TVWwH"
      },
      "id": "zquYt37TVWwH"
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = data.drop(['Ranking_PERC','Ranking_CK','Ranking_CMJ','Ranking_DJ','Ranking_DJCont','Ranking_RSI'], axis=1)\n",
        "X = df2.values"
      ],
      "metadata": {
        "id": "LAZdyQy1FwVc"
      },
      "id": "LAZdyQy1FwVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d6e7ccb",
      "metadata": {
        "id": "2d6e7ccb"
      },
      "source": [
        "## Inspecting and choosing the right data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation\n",
        "correlation=df2.corr()\n",
        "print(correlation)"
      ],
      "metadata": {
        "id": "pNxKGhOZTtJl",
        "collapsed": true
      },
      "id": "pNxKGhOZTtJl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.corr().unstack().sort_values().drop_duplicates()"
      ],
      "metadata": {
        "id": "rgNxF2wjpAxd",
        "collapsed": true
      },
      "id": "rgNxF2wjpAxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4faa6459",
      "metadata": {
        "id": "4faa6459",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#heatmap\n",
        "import seaborn as sns\n",
        "sns.heatmap(correlation, annot=True,fmt=\".1f\",linewidths=.1, linecolor='#ffffff',\n",
        "            cmap='YlGnBu', xticklabels=1, yticklabels=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Age' has a low average correlation with other features and is not strongly correlated with any single feature.\n",
        "\n",
        "The decision to remove 'Age' is based on specific goals of the modeling process, rather than purely on the correlation analysis."
      ],
      "metadata": {
        "id": "jmULfje6bti_"
      },
      "id": "jmULfje6bti_"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset into a pandas DataFrame\n",
        "# Replace 'data.csv' with the path to your dataset\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df2.corr()\n",
        "\n",
        "# Calculate average correlation for each variable\n",
        "average_correlation = correlation_matrix.abs().mean()\n",
        "\n",
        "# Set a threshold for average correlation\n",
        "correlation_threshold = 0.25 # Adjust this threshold as needed\n",
        "\n",
        "# Identify variables with average correlations below the threshold\n",
        "less_correlated_variables = average_correlation[average_correlation < correlation_threshold].index.tolist()\n",
        "\n",
        "# Remove less correlated variables from the DataFrame\n",
        "df_filtered = df2.drop(columns=less_correlated_variables)\n",
        "\n",
        "# Optional: Print the removed variables\n",
        "print(\"Removed Variables:\", less_correlated_variables)\n"
      ],
      "metadata": {
        "id": "-AQpJaEAYFaD",
        "collapsed": true
      },
      "id": "-AQpJaEAYFaD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "45a453b8",
      "metadata": {
        "id": "45a453b8"
      },
      "source": [
        "## **Let's begin the analysis | Factor analysis and principal component analysis (PCA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code aims to perform **factor analysis and principal component analysis** (PCA) on the standardized dataset. It first checks the suitability of the data for factor analysis using **Bartlett's test of sphericity**. Then, it performs PCA and factor analysis with varimax rotation, displaying the loadings. Finally, it visualizes the **factor loadings** and shows the **explained variance ratio** for each principal component."
      ],
      "metadata": {
        "id": "QoxJO6zPe9F0"
      },
      "id": "QoxJO6zPe9F0"
    },
    {
      "cell_type": "markdown",
      "id": "7108ed1f",
      "metadata": {
        "id": "7108ed1f"
      },
      "source": [
        "Now, that we have our data let's begin with our analysis! Firstly we will standardize our data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_filtered.values"
      ],
      "metadata": {
        "id": "VRNngJ8nmzdl"
      },
      "id": "VRNngJ8nmzdl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standardizing our data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Standardize and scale the data\n",
        "data_new = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "GmVQYk3gT3dE"
      },
      "id": "GmVQYk3gT3dE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_new)"
      ],
      "metadata": {
        "id": "Cvv4Qm3MtTCs",
        "collapsed": true
      },
      "id": "Cvv4Qm3MtTCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install factor-analyzer"
      ],
      "metadata": {
        "id": "L9RuCCDDUOfw",
        "collapsed": true
      },
      "id": "L9RuCCDDUOfw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bartlett's Test**\n",
        "\n",
        "Assess the suitability of the data for factor analysis. The heatmap provides a clear overview of the relationships between variables."
      ],
      "metadata": {
        "id": "-WvGy0dYUew9"
      },
      "id": "-WvGy0dYUew9"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IUbXiwILUHuQ"
      },
      "id": "IUbXiwILUHuQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module that performs the Bartlett test\n",
        "import factor_analyzer\n",
        "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
        "chi_square_value, p_value = calculate_bartlett_sphericity(data_new)\n",
        "print('Bartlett Sphericity Test: chiÂ² = %d,  p_value = %d' % (chi_square_value, p_value))"
      ],
      "metadata": {
        "id": "T6kU759hSTXD",
        "collapsed": true
      },
      "id": "T6kU759hSTXD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5e41cf96",
      "metadata": {
        "id": "5e41cf96"
      },
      "source": [
        "Now, we will continue with the PCA part. Taking into account the <u> <i> <b> Kaiser's </b> </i> </u>  criterion which states that the components that have an eigenvalue greater than 1 are selected, we will choose the first 4 principal components. Thus, by making PCA we achieved to explain 82% of our data's variance <u> only by looking at a four-dimensional space. </u>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = df_filtered.columns\n",
        "feature_names"
      ],
      "metadata": {
        "id": "u5y7FszJgm_1",
        "collapsed": true
      },
      "id": "u5y7FszJgm_1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_filtered.values"
      ],
      "metadata": {
        "id": "ayomI_PVj1ZG"
      },
      "id": "ayomI_PVj1ZG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(X)\n",
        "X_scaled = std_scale.transform(X)"
      ],
      "metadata": {
        "id": "ttg9bS7u0a4c"
      },
      "id": "ttg9bS7u0a4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Number of Principal Components - PCA**"
      ],
      "metadata": {
        "id": "mRJePXEWU6Uk"
      },
      "id": "mRJePXEWU6Uk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition\n",
        "\n",
        "pca = decomposition.PCA(n_components=4)\n",
        "pca.fit(X_scaled)"
      ],
      "metadata": {
        "id": "TGbmD1-L0gkn",
        "collapsed": true
      },
      "id": "TGbmD1-L0gkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (pca.explained_variance_ratio_)\n",
        "print (pca.explained_variance_ratio_.sum())"
      ],
      "metadata": {
        "id": "A-soSlXU0k5o",
        "collapsed": true
      },
      "id": "A-soSlXU0k5o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VARIMAX Method**\n",
        "\n",
        "VARIMAX, short for \"variance maximizing rotation,\" is a type of orthogonal rotation method. Orthogonal rotations keep the factors uncorrelated (independent) from each other, which simplifies interpretation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iD73NOjvVV42"
      },
      "id": "iD73NOjvVV42"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "\n",
        "n_comps = 4\n",
        "\n",
        "methods = [\n",
        "    (\"PCA\", PCA(n_components=n_comps)),\n",
        "    (\"Unrotated Loadings\", FactorAnalysis(n_components=n_comps)),\n",
        "    (\"Varimax-Rotated Loadings\", FactorAnalyzer(n_factors=n_comps, rotation=\"varimax\"))\n",
        "]\n",
        "\n",
        "# Assuming X_scaled is your standardized dataset\n",
        "for method, model in methods:\n",
        "    model.fit(X_scaled)\n",
        "    if method == \"PCA\":\n",
        "        loadings = model.components_.T\n",
        "    elif method == \"Varimax-Rotated Loadings\":\n",
        "        loadings = model.loadings_\n",
        "    else:  # For Unrotated FA\n",
        "        loadings = model.components_.T\n",
        "\n",
        "    communalities = np.sum(loadings ** 2, axis=1)\n",
        "\n",
        "    # Create DataFrame\n",
        "    table = pd.DataFrame(data=loadings, columns=[f'Factor {i+1}' for i in range(n_comps)])\n",
        "    table['Communalities'] = communalities\n",
        "    table.index = feature_names  # Assuming feature_names is defined\n",
        "\n",
        "    print(f\"\\n\\n {method} :\\n\")\n",
        "    print(table)"
      ],
      "metadata": {
        "id": "7Gk_FQhPHQWD",
        "collapsed": true
      },
      "id": "7Gk_FQhPHQWD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "\n",
        "n_comps = 4\n",
        "\n",
        "methods = [\n",
        "    (\"PCA\", PCA(n_components=n_comps)),  # Exclude PCA method\n",
        "    (\"Unrotated FA\", FactorAnalysis()),\n",
        "    (\"Varimax FA\", FactorAnalyzer(n_factors=n_comps, rotation=\"varimax\"))\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(ncols=len(methods), figsize=(15, 8), sharey=True)\n",
        "\n",
        "for ax, (method, model) in zip(axes, methods):\n",
        "    model.fit(X_scaled)  # Supondo que X_scaled seja o seu conjunto de dados padronizado\n",
        "\n",
        "    if method == \"PCA\":\n",
        "        components = model.components_.T\n",
        "    elif method == \"Varimax FA\":\n",
        "        components = model.loadings_\n",
        "\n",
        "    print(\"\\n\\n %s :\\n\" % method)\n",
        "    print(components)\n",
        "\n",
        "    vmax = np.abs(components).max()\n",
        "    ax.imshow(components, cmap=\"RdBu\", vmax=vmax, vmin=-vmax)\n",
        "    ax.set_yticks(np.arange(len(feature_names)))\n",
        "    ax.set_yticklabels(feature_names)\n",
        "    ax.set_title(str(method))\n",
        "    ax.set_xticks(np.arange(n_comps))\n",
        "    ax.set_xticklabels([\"Comp. {}\".format(i+1) for i in range(n_comps)])\n",
        "\n",
        "fig.suptitle(\"Factors\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('factors_PCA_Varimax.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7KZUZMgsFG4t",
        "collapsed": true
      },
      "id": "7KZUZMgsFG4t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Varimax-rotated factor analysis reveals four distinct factors underlying the relationships between the variables in the dataset:\n",
        "\n",
        "**Factor 1**: Strength: This factor is primarily characterized by high positive loadings on variables related to body composition (Weight (kg), %Body Fat) and measures of strength (1RM Hip Thrust (kg), Relative 1RM HT(kg), Relative 1RM Squat (kg)).\n",
        "\n",
        "**Factor 2**: Lower Body Power and Explosiveness: This factor is dominated by high positive loadings on Baseline Drop Jump (cm) and Baseline CMJ (cm), both of which are measures of lower body power and explosiveness.\n",
        "\n",
        "**Factor 3**: Speed and Agility: This factor is defined by high positive loadings on Speed 5m (s) and Speed 20m (s).\n",
        "\n",
        "**Factor 4**: This factor has a high positive loading on Weight (kg), and %Body Fat.\n",
        "\n",
        "These interpretations provide insights into the underlying structure of the data and how the variables relate to each other. Each factor represents a distinct dimension of physical fitness, and individuals can be characterized by their scores on these factors."
      ],
      "metadata": {
        "id": "R5yMWdd-VpS0"
      },
      "id": "R5yMWdd-VpS0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cumulative Explained Variance**\n",
        "\n",
        "This section visualizes the cumulative explained variance ratio for the principal components. It shows how much of the total variance in the data is captured by increasing the number of components. This information helps assess the trade-off between dimensionality reduction and information retention."
      ],
      "metadata": {
        "id": "akPQoHIQWTmY"
      },
      "id": "akPQoHIQWTmY"
    },
    {
      "cell_type": "code",
      "source": [
        "#making the pca\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=13,svd_solver=\"full\")\n",
        "pca.fit(X_scaled)\n",
        "#taking the explained variance (eigenvalue) for each component\n",
        "variance=pca.explained_variance_\n",
        "#explained variance ratio\n",
        "variance_ratio=(pca.explained_variance_ratio_)*100\n",
        "#cumulative explained variance ratio\n",
        "cum=np.cumsum(variance_ratio)\n",
        "#bulding a dataframe\n",
        "names=df_filtered.columns\n",
        "table=pd.DataFrame({'Variable name':names,'Eigenvalue':variance,'% of explained variance ratio':variance_ratio,'% of cumulative explained variance ratio':cum})\n",
        "print(table)"
      ],
      "metadata": {
        "id": "POm8Csf0Uq8m",
        "collapsed": true
      },
      "id": "POm8Csf0Uq8m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5f4b5e9",
      "metadata": {
        "id": "f5f4b5e9"
      },
      "source": [
        "Let's make the <b> scree plot </b> that is another way of judging which components it would be good to choose!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_projected = pca.transform(data_new)\n",
        "print (X_projected.shape)"
      ],
      "metadata": {
        "id": "kyweHzdp1NVl",
        "collapsed": true
      },
      "id": "kyweHzdp1NVl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Explained variance obtained from your code\n",
        "explained_variance = variance_ratio\n",
        "eigenvalues = variance\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot percentage of variance explained\n",
        "ax1.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', color='skyblue', label='% Variance Explained')\n",
        "ax1.set_xlabel('Principal Component')\n",
        "ax1.set_ylabel('% of Variance Explained', color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "# ax1.legend(loc='upper left')\n",
        "\n",
        "# Plot eigenvalues on the secondary y-axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o', color='orange', label='Eigenvalues')\n",
        "ax2.set_ylabel('Eigenvalues', color='black')\n",
        "ax2.tick_params(axis='y', labelcolor='black')\n",
        "# ax2.legend(loc='upper right')\n",
        "\n",
        "# Annotate explained variance points\n",
        "for i, var in enumerate(explained_variance):\n",
        "    ax1.annotate(f'{var:.2f}%', (i + 1, var), textcoords=\"offset points\", xytext=(0, 5), ha='center', fontweight='bold')\n",
        "\n",
        "# Set x-axis ticks and labels for every component\n",
        "ax1.set_xticks(np.arange(1, len(explained_variance) + 1))\n",
        "ax1.set_xticklabels(np.arange(1, len(explained_variance) + 1))\n",
        "\n",
        "#plt.title('Scree Plot')\n",
        "plt.tight_layout()\n",
        "sns.despine(left=True)\n",
        "sns.axes_style(\"whitegrid\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SyHBLZjv9V5T",
        "collapsed": true
      },
      "id": "SyHBLZjv9V5T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iKIFxDAGVMJf"
      },
      "id": "iKIFxDAGVMJf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing Method"
      ],
      "metadata": {
        "id": "fwkFu7fyHMiN"
      },
      "id": "fwkFu7fyHMiN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of New Samples Generated"
      ],
      "metadata": {
        "id": "OjtJuiEs6MjM"
      },
      "id": "OjtJuiEs6MjM"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "id": "MnCbaplXkAl6",
        "collapsed": true
      },
      "id": "MnCbaplXkAl6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "x_train_full, x_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(x_train_full, y_train_full)\n",
        "\n",
        "# Print the number of new samples generated by SMOTE\n",
        "print(f\"Original training data shape: {x_train_full.shape[0]} samples, {x_train_full.shape[1]} features\")\n",
        "print(f\"Resampled training data shape: {X_resampled.shape[0]} samples, {X_resampled.shape[1]} features\")\n",
        "print(f\"Number of new samples generated by SMOTE: {X_resampled.shape[0] - x_train_full.shape[0]}\")\n",
        "print(f\"Percentage increase in data points: {(X_resampled.shape[0] - x_train_full.shape[0]) / x_train_full.shape[0] * 100:.2f}%\")\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(x_train_full, y_train_full)\n",
        "\n",
        "# Calculate the number of minority class samples needed to reach the desired ratio\n",
        "minority_class_samples = 8\n",
        "\n",
        "# Select the desired number of minority class samples\n",
        "minority_class_indices = np.where(y_resampled_adasyn == 1)[0]\n",
        "selected_minority_class_indices = np.random.choice(minority_class_indices, size=minority_class_samples, replace=True)\n",
        "\n",
        "# Create the final resampled dataset\n",
        "X_resampled_adasyn_final = np.concatenate((x_train_full, X_resampled_adasyn[selected_minority_class_indices]))\n",
        "y_resampled_adasyn_final = np.concatenate((y_train_full, y_resampled_adasyn[selected_minority_class_indices]))\n",
        "\n",
        "# Print the number of new samples generated by ADASYN\n",
        "print(f\"Original training data shape: {x_train_full.shape[0]} samples, {x_train_full.shape[1]} features\")\n",
        "print(f\"Resampled training data shape: {X_resampled_adasyn_final.shape[0]} samples, {X_resampled_adasyn_final.shape[1]} features\")\n",
        "print(f\"Number of new samples generated by ADASYN: {X_resampled_adasyn_final.shape[0] - x_train_full.shape[0]}\")\n",
        "print(f\"Percentage increase in data points: {(X_resampled_adasyn_final.shape[0] - x_train_full.shape[0]) / x_train_full.shape[0] * 100:.2f}%\")\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled_ros, y_resampled_ros = ros.fit_resample(x_train_full, y_train_full)\n",
        "\n",
        "# Print the number of new samples generated by ROS\n",
        "print(f\"Original training data shape: {x_train_full.shape[0]} samples, {x_train_full.shape[1]} features\")\n",
        "print(f\"Resampled training data shape: {X_resampled_ros.shape[0]} samples, {X_resampled_ros.shape[1]} features\")\n",
        "print(f\"Number of new samples generated by ROS: {X_resampled_ros.shape[0] - x_train_full.shape[0]}\")\n",
        "print(f\"Percentage increase in data points: {(X_resampled_ros.shape[0] - x_train_full.shape[0]) / x_train_full.shape[0] * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "ozAziMNC4Y80",
        "collapsed": true
      },
      "id": "ozAziMNC4Y80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note that we have to run these cells, e.g. the following cells of Perception rank, every time before we run the models, because the data have to be set up accordingly to the rank that will be predicted.**"
      ],
      "metadata": {
        "id": "Baj10Di32CmA"
      },
      "id": "Baj10Di32CmA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking Perception Prediction: Data Preprocessing and Model Training**\n",
        "\n",
        "The code starts by creating a binary target variable (Reviews_Perc) based on the Ranking_PERC column. Values between 1 and 21 are labeled as '0' (top 20), and values between 22 and 41 are labeled as '1' (next 20).\n",
        "\n",
        "The PCA-transformed data (X_projected) is used as the feature set.\n",
        "The data is split into training and testing sets using a 75%/25% split.\n",
        "\n"
      ],
      "metadata": {
        "id": "NuE7I311evNN"
      },
      "id": "NuE7I311evNN"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the bin edges\n",
        "bin_edges = [0, 21, 41]  # 0-20 (top 20), 21-40 (next 20)\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "# Use the cut function to create categorical labels\n",
        "reviews = data['Reviews_Perc'] = pd.cut(data['Ranking_PERC'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "pPR4tJIXCIBN"
      },
      "id": "pPR4tJIXCIBN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_PERC']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_Perc'] = reviews"
      ],
      "metadata": {
        "id": "JxGznOZdYg9f"
      },
      "id": "JxGznOZdYg9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Reviews_Perc']"
      ],
      "metadata": {
        "id": "drc5wqO7SQEP"
      },
      "id": "drc5wqO7SQEP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y, test_size = 0.25, random_state=42)"
      ],
      "metadata": {
        "id": "1ROx8nEROPJx"
      },
      "id": "1ROx8nEROPJx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "RVrshQMHz9zB"
      },
      "id": "RVrshQMHz9zB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**\n",
        "\n",
        "The code starts by encoding the target variable (y) into numerical format using LabelEncoder.\n",
        "\n",
        "The data is split into training and testing sets, with 25% reserved for testing.\n",
        "\n",
        "Several classifier models are initialized: Random Forest, Naive Bayes, SVM, AdaBoost, and XGBoost.\n",
        "\n",
        "Random Over-Sampling (ROSE) is applied to the training data. This technique generates synthetic samples of the minority class to balance the class distribution, addressing the issue of imbalanced data.\n",
        "\n",
        "**Explanation**:\n",
        "\n",
        "The code iterates through each classifier model.\n",
        "Each model is trained on the **oversampled data** (***x_resampled, y_resampled***).\n",
        "\n",
        "The model is used to predict the target variable for the test set (x_test).\n",
        "Model performance is evaluated using various metrics (**accuracy, precision, recall, F1-score**) and a **confusion matrix** is printed.\n",
        "\n",
        "For the Random Forest model specifically:\n",
        "**Feature importances** are calculated and displayed.\n",
        "A horizontal bar plot is created to visualize the relative importance of each feature in the model."
      ],
      "metadata": {
        "id": "Vg_E8dj8hJvQ"
      },
      "id": "Vg_E8dj8hJvQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jTZI6JMBkBlg"
      },
      "id": "jTZI6JMBkBlg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "x_train_full, x_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "# Further split the training data into 80% training and 20% validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "# Initialize classifiers with random_state\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=RANDOM_SEED),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(random_state=RANDOM_SEED),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=RANDOM_SEED),\n",
        "    'XGBoost': XGBClassifier(random_state=RANDOM_SEED)\n",
        "}\n",
        "\n",
        "# Initialize 5-fold cross-validation within the training set\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "# To store overall metrics and confusion matrices\n",
        "metrics = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'conf_matrix': []} for name in classifiers.keys()}\n",
        "\n",
        "# Cross-validation loop on the training set\n",
        "for train_index, val_index in kf.split(x_train):\n",
        "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
        "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Apply oversampling to the training fold\n",
        "    ros = RandomOverSampler(random_state=RANDOM_SEED)\n",
        "    x_resampled, y_resampled = ros.fit_resample(x_train_kf, y_train_kf)\n",
        "\n",
        "    # Train and evaluate classifiers on validation fold\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(x_resampled, y_resampled)\n",
        "        y_pred = clf.predict(x_val_kf)\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc = accuracy_score(y_val_kf, y_pred)\n",
        "        precision = precision_score(y_val_kf, y_pred, pos_label=1)\n",
        "        recall = recall_score(y_val_kf, y_pred, pos_label=1)\n",
        "        f1 = f1_score(y_val_kf, y_pred, pos_label=1)\n",
        "        conf_matrix = confusion_matrix(y_val_kf, y_pred)\n",
        "\n",
        "        # Store metrics\n",
        "        metrics[name]['accuracy'].append(acc)\n",
        "        metrics[name]['precision'].append(precision)\n",
        "        metrics[name]['recall'].append(recall)\n",
        "        metrics[name]['f1'].append(f1)\n",
        "        metrics[name]['conf_matrix'].append(conf_matrix)\n",
        "\n",
        "# Print the average results for each classifier on the validation set\n",
        "for name in classifiers.keys():\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Average Validation Accuracy: {np.mean(metrics[name]['accuracy'])}\")\n",
        "    print(f\"Average Validation Precision: {np.mean(metrics[name]['precision'])}\")\n",
        "    print(f\"Average Validation Recall: {np.mean(metrics[name]['recall'])}\")\n",
        "    print(f\"Average Validation F1-score: {np.mean(metrics[name]['f1'])}\")\n",
        "\n",
        "\n",
        "# Final evaluation on the test set\n",
        "print(\"\\nFinal evaluation on the test set:\")\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_train, y_train)  # Train on the full training set\n",
        "    y_pred_test = clf.predict(x_test)\n",
        "\n",
        "    # Calculate metrics on the test set\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "    precision_test = precision_score(y_test, y_pred_test, pos_label=1)\n",
        "    recall_test = recall_score(y_test, y_pred_test, pos_label=1)\n",
        "    f1_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
        "    conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    # Print test set metrics\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Test Accuracy: {acc_test}\")\n",
        "    print(f\"Test Precision: {precision_test}\")\n",
        "    print(f\"Test Recall: {recall_test}\")\n",
        "    print(f\"Test F1-score: {f1_test}\")\n",
        "    print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cxljtubhQw7O",
        "collapsed": true
      },
      "id": "cxljtubhQw7O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper-parameter Tuning with Cross-Validation\n"
      ],
      "metadata": {
        "id": "cCfoc7FsauZY"
      },
      "id": "cCfoc7FsauZY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "ATseEoOCJip3"
      },
      "id": "ATseEoOCJip3"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6GBYEwOw41k4"
      },
      "id": "6GBYEwOw41k4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "LlV_FIDQ_ShQ",
        "collapsed": true
      },
      "id": "LlV_FIDQ_ShQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "aju2WNY2ASVm",
        "collapsed": true
      },
      "id": "aju2WNY2ASVm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming best_model is the best AdaBoost model obtained from GridSearchCV\n",
        "# and X_resampled_full is the resampled training data used for fitting best_model\n",
        "\n",
        "# Define a function to get model predictions\n",
        "def predict_fn(X):\n",
        "    return best_model.predict_proba(X)\n",
        "\n",
        "# Initialize SHAP Explainer\n",
        "explainer = shap.KernelExplainer(predict_fn, X_resampled_full)\n",
        "\n",
        "# Compute SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Print the shape of SHAP values for debugging\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "# Check if SHAP values are a list (binary classification scenario)\n",
        "if isinstance(shap_values, list):\n",
        "    # Extract SHAP values for the positive class (usually the second class)\n",
        "    shap_values_class = shap_values[1]\n",
        "else:\n",
        "    # If not a list, assume it's already for the positive class\n",
        "    shap_values_class = shap_values\n",
        "\n",
        "# Ensure SHAP values are 2D with shape (num_samples, num_features)\n",
        "if shap_values_class.ndim == 3:\n",
        "    # If 3D, handle the case appropriately\n",
        "    shap_values_class = shap_values_class[:, :, 1]  # Select the SHAP values for the positive class if 3D\n",
        "elif shap_values_class.ndim != 2:\n",
        "    raise ValueError(f\"Unexpected SHAP values shape: {shap_values_class.shape}\")\n",
        "\n",
        "# Calculate mean absolute SHAP values for feature importance\n",
        "mean_shap_values = np.mean(np.abs(shap_values_class), axis=0)\n",
        "\n",
        "# Get feature names directly from the DataFrame\n",
        "feature_names = df_filtered.columns.tolist()\n",
        "\n",
        "# Ensure lengths match\n",
        "if len(feature_names) != len(mean_shap_values):\n",
        "    print(f\"Length mismatch: feature_names ({len(feature_names)}) != mean_shap_values ({len(mean_shap_values)})\")\n",
        "    # Optionally handle the mismatch here\n",
        "\n",
        "# Ensure 1D arrays\n",
        "feature_names = np.array(feature_names).flatten()\n",
        "mean_shap_values = np.array(mean_shap_values).flatten()\n",
        "\n",
        "# Create a DataFrame to show feature importances\n",
        "try:\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': mean_shap_values\n",
        "    })\n",
        "    # Print feature importances\n",
        "    print(\"\\nFeature Importances using SHAP for Best AdaBoost Model:\")\n",
        "    print(importance_df)\n",
        "except ValueError as e:\n",
        "    print(f\"Error creating DataFrame: {e}\")\n",
        "\n",
        "# Plot SHAP summary plot\n",
        "shap.summary_plot(shap_values_class, X_test)\n"
      ],
      "metadata": {
        "id": "IKz0kVT1Ls3q",
        "collapsed": true
      },
      "id": "IKz0kVT1Ls3q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Cross Validation if you want to test it"
      ],
      "metadata": {
        "id": "U8mMinahJvgc"
      },
      "id": "U8mMinahJvgc"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply ROSE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "__pUAUJRVcDn",
        "collapsed": true
      },
      "id": "__pUAUJRVcDn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the **only difference** in the code below is that **Feature importances** are calculated and displayed.\n",
        "\n",
        "**You will see this pattern in this code.**\n",
        "\n"
      ],
      "metadata": {
        "id": "Cz3ItU_coCsJ"
      },
      "id": "Cz3ItU_coCsJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'Random Forest':\n",
        "        variable_importance = clf.feature_importances_\n",
        "        print(f\"\\nVariable Importance for {name}:\")\n",
        "        for idx, importance in enumerate(variable_importance):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot variable importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, variable_importance, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        #plt.ylabel('Feature')\n",
        "        #plt.title('Variable Importance for Random Forest Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        '''for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(variable_importance[idx], 2),\n",
        "                     va='center', ha='left')'''\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "3rnBuO4vvqBu",
        "collapsed": true
      },
      "id": "3rnBuO4vvqBu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "4hu7W7IzDw3q"
      },
      "id": "4hu7W7IzDw3q"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "RhrlUKa2IJC8"
      },
      "id": "RhrlUKa2IJC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "SePR__F3FXPa"
      },
      "id": "SePR__F3FXPa"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_full, x_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(x_train_full, y_train_cv)\n",
        "\n",
        "# Print the number of new samples generated by SMOTE\n",
        "print(f\"Original training data shape: {X_train_cv.shape[0]} samples, {X_train_cv.shape[1]} features\")\n",
        "print(f\"Resampled training data shape: {X_resampled.shape[0]} samples, {X_resampled.shape[1]} features\")\n",
        "print(f\"Number of new samples generated by SMOTE: {X_resampled.shape[0] - X_train_cv.shape[0]}\")\n",
        "print(f\"Percentage increase in data points: {(X_resampled.shape[0] - X_train_cv.shape[0]) / X_train_cv.shape[0] * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "gZzTzkYx3uZz"
      },
      "id": "gZzTzkYx3uZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "        model.fit(x_resampled, y_resampled)\n",
        "        train_pred = model.predict(x_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply Smote to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "efzLCInLB6Hz",
        "collapsed": true
      },
      "id": "efzLCInLB6Hz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris  # Example dataset, replace with your data\n",
        "\n",
        "# Assuming the best model parameters from GridSearchCV\n",
        "best_params = {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
        "\n",
        "# Initialize the Random Forest with the best parameters\n",
        "rf_best = RandomForestClassifier(**best_params, random_state=42)\n",
        "\n",
        "# Fit the model to the entire training data (if you're using the entire dataset)\n",
        "rf_best.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Extract feature importances\n",
        "importances = rf_best.feature_importances_\n",
        "features = df_filtered.columns  # Assuming X_train_full is a DataFrame\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances['Feature'], feature_importances['Importance'], color='skyblue')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances from Random Forest')\n",
        "plt.gca().invert_yaxis()  # To display the most important features at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ghrRlk7BNnEh",
        "collapsed": true
      },
      "id": "ghrRlk7BNnEh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f-JCmYpFQhC2",
        "collapsed": true
      },
      "id": "f-JCmYpFQhC2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "-RDgqLVoF-ml"
      },
      "id": "-RDgqLVoF-ml"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "C_Hz3txhFpk2"
      },
      "id": "C_Hz3txhFpk2"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ADASYN to training data\n",
        "        adasyn = ADASYN(random_state=42)\n",
        "        x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "        model.fit(x_resampled, y_resampled)\n",
        "        train_pred = model.predict(x_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        adasyn = ADASYN(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        adasyn = ADASYN(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Dqv_s1qxFpA4",
        "collapsed": true
      },
      "id": "Dqv_s1qxFpA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=42)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LUN_kP-lQBe4",
        "collapsed": true
      },
      "id": "LUN_kP-lQBe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking CK Prediction**\n",
        "\n",
        "Here you can find the best combination for CK"
      ],
      "metadata": {
        "id": "vXzHbnciegno"
      },
      "id": "vXzHbnciegno"
    },
    {
      "cell_type": "code",
      "source": [
        "bin_edges = [0, 21, 41]  # Defining bins (0-20, 21-40)\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "# Apply pd.cut to create the 'Reviews_CK' column\n",
        "reviews2 = data['Reviews_CK'] = pd.cut(data['Ranking_CK'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "ak2265vNZHdV"
      },
      "id": "ak2265vNZHdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_CK']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_CK'] = reviews"
      ],
      "metadata": {
        "id": "ggbLQdcLz9Po"
      },
      "id": "ggbLQdcLz9Po",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = data['Reviews_CK']\n"
      ],
      "metadata": {
        "id": "014mbziil4IL"
      },
      "id": "014mbziil4IL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "6J1HynAya2HM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "6J1HynAya2HM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**"
      ],
      "metadata": {
        "id": "XfWCkexhbjsC"
      },
      "id": "XfWCkexhbjsC"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "LxNIXEwlbjsL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LxNIXEwlbjsL"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y2)"
      ],
      "metadata": {
        "id": "COCgj0sTfvzV"
      },
      "id": "COCgj0sTfvzV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "c7GJ2nXvHo-7"
      },
      "id": "c7GJ2nXvHo-7"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "HLKXGw_QHsgC",
        "collapsed": true
      },
      "id": "HLKXGw_QHsgC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y2)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "Eic5PbKUbjsL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "Eic5PbKUbjsL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "-r_Ytajrf4bl"
      },
      "id": "-r_Ytajrf4bl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can find the best combination for CK: **SMOTE and XGBoost**"
      ],
      "metadata": {
        "id": "DNVY2x7Unpv4"
      },
      "id": "DNVY2x7Unpv4"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "IAY0PT6Tf4bw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IAY0PT6Tf4bw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "saWs_0oMHzRM"
      },
      "id": "saWs_0oMHzRM"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with SMOTE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply SMOTE to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply SMOTE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VTTx_McVH0fA",
        "collapsed": true
      },
      "id": "VTTx_McVH0fA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y2)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R6m7EYXgf4bx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "R6m7EYXgf4bx"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y2)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'XGBoost':\n",
        "        variable_importance = clf.feature_importances_\n",
        "        print(f\"\\nVariable Importance for {name}:\")\n",
        "        for idx, importance in enumerate(variable_importance):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot variable importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, variable_importance, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        #plt.ylabel('Feature')\n",
        "        #plt.title('Variable Importance for Random Forest Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        '''for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(variable_importance[idx], 2),\n",
        "                     va='center', ha='left')'''\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "yJR2elUoKVIs",
        "collapsed": true
      },
      "id": "yJR2elUoKVIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "OV8J575fhajA"
      },
      "id": "OV8J575fhajA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "FiJr9t4ZH3iB"
      },
      "id": "FiJr9t4ZH3iB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        model.fit(X_train_cv, y_train_cv)\n",
        "        train_pred = model.predict(X_train_cv)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=LeaveOneOut(),\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(x_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        model.fit(X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        y_test_pred = model.predict(x_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "fPisidU0H48C",
        "collapsed": true
      },
      "id": "fPisidU0H48C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming best_model is the best XGBoost model obtained from GridSearchCV\n",
        "# and X_resampled_full is the resampled training data used for fitting best_model\n",
        "\n",
        "# Define SHAP explainer for XGBoost\n",
        "explainer = shap.Explainer(best_model)\n",
        "\n",
        "# Compute SHAP values for the test set\n",
        "shap_values = explainer(x_test)\n",
        "\n",
        "# Print the shape of SHAP values for debugging\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "# Extract feature names directly from X_test DataFrame\n",
        "feature_names = df_filtered.columns.tolist()\n",
        "\n",
        "# Calculate mean absolute SHAP values for feature importance\n",
        "mean_shap_values = np.mean(np.abs(shap_values.values), axis=0) / np.sum(np.abs(shap_values.values))\n",
        "\n",
        "# Ensure lengths match\n",
        "if len(feature_names) != len(mean_shap_values):\n",
        "    print(f\"Length mismatch: feature_names ({len(feature_names)}) != mean_shap_values ({len(mean_shap_values)})\")\n",
        "    raise ValueError(\"Length mismatch\")\n",
        "\n",
        "# Ensure 1D arrays\n",
        "feature_names = np.array(feature_names).flatten()\n",
        "mean_shap_values = np.array(mean_shap_values).flatten()\n",
        "\n",
        "# Create a DataFrame to show feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': mean_shap_values\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances using SHAP for Best XGBoost Model:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Save the importance DataFrame to a file\n",
        "importance_df.to_csv('feature_importances_CK.csv', index=False)\n",
        "\n",
        "# Plot SHAP summary plot\n",
        "shap.summary_plot(shap_values, x_test)\n"
      ],
      "metadata": {
        "id": "DsSfmeE9Rhuc",
        "collapsed": true
      },
      "id": "DsSfmeE9Rhuc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y2)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=4)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=4)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rXoO4iS-hajB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "rXoO4iS-hajB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking CMJ Prediction**\n",
        "\n",
        "Here you can find the best combination for CMJ"
      ],
      "metadata": {
        "id": "0Y6Lwx_jk2YS"
      },
      "id": "0Y6Lwx_jk2YS"
    },
    {
      "cell_type": "code",
      "source": [
        "bin_edges = [0, 21, 41]  # 0-20 (top 20), 21-40 (next 20)\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "reviews3 = data['Reviews_CMJ'] = pd.cut(data['Ranking_CMJ'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "lLAr9o2YlSv8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lLAr9o2YlSv8"
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_CMJ']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_CMJ'] = reviews"
      ],
      "metadata": {
        "id": "pMN80Sdjdjqd"
      },
      "id": "pMN80Sdjdjqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = data['Reviews_CMJ']\n",
        "y3"
      ],
      "metadata": {
        "id": "Y46aAYj2lSv8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y46aAYj2lSv8"
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "eJw6LQPflSv9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "eJw6LQPflSv9"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y3)"
      ],
      "metadata": {
        "id": "LeP2I4PKjgeX"
      },
      "id": "LeP2I4PKjgeX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**"
      ],
      "metadata": {
        "id": "cA5IozgglSv-"
      },
      "id": "cA5IozgglSv-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "5abpVPE2I9Ur"
      },
      "id": "5abpVPE2I9Ur"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "89NLWcgy1F7z"
      },
      "id": "89NLWcgy1F7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7N_yE6tlJAJ_",
        "collapsed": true
      },
      "id": "7N_yE6tlJAJ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "Koph8SCHlSv-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Koph8SCHlSv-"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y3)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "2P_jSkdClSv_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "2P_jSkdClSv_"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y3)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'Random Forest':\n",
        "        variable_importance = clf.feature_importances_\n",
        "        print(f\"\\nVariable Importance for {name}:\")\n",
        "        for idx, importance in enumerate(variable_importance):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot variable importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, variable_importance, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        #plt.ylabel('Feature')\n",
        "        #plt.title('Variable Importance for Random Forest Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        '''for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(variable_importance[idx], 2),\n",
        "                     va='center', ha='left')'''\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "kVuKGq1WLjsa",
        "collapsed": true
      },
      "id": "kVuKGq1WLjsa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "rBO8WuDYlSv_"
      },
      "id": "rBO8WuDYlSv_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "2ZlSKaUBJO1A"
      },
      "id": "2ZlSKaUBJO1A"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with SMOTE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply SMOTE to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply SMOTE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "99eCuafVJbk_",
        "collapsed": true
      },
      "id": "99eCuafVJbk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "A0DqJzBulSwA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "A0DqJzBulSwA"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y3)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OF5vSI5SlSwA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "OF5vSI5SlSwA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "8vckgfcFlSwA"
      },
      "id": "8vckgfcFlSwA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "oA3uyHyOJYJe"
      },
      "id": "oA3uyHyOJYJe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=RANDOM_SEED),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(random_state=RANDOM_SEED),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=RANDOM_SEED),\n",
        "    'XGBoost': XGBClassifier(random_state=RANDOM_SEED)\n",
        "}"
      ],
      "metadata": {
        "id": "EAKrIo9a1n_k"
      },
      "id": "EAKrIo9a1n_k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        model.fit(X_train_cv, y_train_cv)\n",
        "        train_pred = model.predict(X_train_cv)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=LeaveOneOut(),\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(x_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        model.fit(X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        y_test_pred = model.predict(x_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_resampled_adasyn_final, y_resampled_adasyn_final)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "7PF3coNKJaBi",
        "collapsed": true
      },
      "id": "7PF3coNKJaBi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming best_model is the best XGBoost model obtained from GridSearchCV\n",
        "# and X_resampled_full is the resampled training data used for fitting best_model\n",
        "\n",
        "# Define SHAP explainer for XGBoost\n",
        "explainer = shap.Explainer(best_model)\n",
        "\n",
        "# Compute SHAP values for the test set\n",
        "shap_values = explainer(x_test)\n",
        "\n",
        "# Print the shape of SHAP values for debugging\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "# Extract feature names directly from X_test DataFrame\n",
        "feature_names = df_filtered.columns.tolist()\n",
        "\n",
        "# Calculate mean absolute SHAP values for feature importance\n",
        "mean_shap_values = np.mean(np.abs(shap_values.values), axis=0) / np.sum(np.abs(shap_values.values))\n",
        "\n",
        "# Ensure lengths match\n",
        "if len(feature_names) != len(mean_shap_values):\n",
        "    print(f\"Length mismatch: feature_names ({len(feature_names)}) != mean_shap_values ({len(mean_shap_values)})\")\n",
        "    raise ValueError(\"Length mismatch\")\n",
        "\n",
        "# Ensure 1D arrays\n",
        "feature_names = np.array(feature_names).flatten()\n",
        "mean_shap_values = np.array(mean_shap_values).flatten()\n",
        "\n",
        "# Create a DataFrame to show feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': mean_shap_values\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances using SHAP for Best XGBoost Model:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Save the importance DataFrame to a file\n",
        "importance_df.to_csv('feature_importances_CMJ.csv', index=False)\n",
        "\n",
        "# Plot SHAP summary plot\n",
        "shap.summary_plot(shap_values, x_test)\n"
      ],
      "metadata": {
        "id": "CWpy2GGbUyqu",
        "collapsed": true
      },
      "id": "CWpy2GGbUyqu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y3)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=4)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=4)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hqRrVX0XlSwB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "hqRrVX0XlSwB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking DJ Prediction**"
      ],
      "metadata": {
        "id": "lGZwZLgenM02"
      },
      "id": "lGZwZLgenM02"
    },
    {
      "cell_type": "code",
      "source": [
        "bin_edges = [0, 21, 41]  # 0-20 (top 20), 21-40 (next 20)\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "reviews3 = data['Reviews_DJ'] = pd.cut(data['Ranking_DJ'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "DRVyLfqCnM02"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DRVyLfqCnM02"
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_DJ']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_DJ'] = reviews"
      ],
      "metadata": {
        "id": "5pduNRB_sZyU"
      },
      "id": "5pduNRB_sZyU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y4 = data['Reviews_DJ']"
      ],
      "metadata": {
        "id": "Sjz3n5LjnM03"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Sjz3n5LjnM03"
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "QXuLkN_gnM03",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "QXuLkN_gnM03"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y4)"
      ],
      "metadata": {
        "id": "pfan_DaCjmcw"
      },
      "id": "pfan_DaCjmcw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**"
      ],
      "metadata": {
        "id": "OeXeaanhnM03"
      },
      "id": "OeXeaanhnM03"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "r6kHiAwCJ0kQ"
      },
      "id": "r6kHiAwCJ0kQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "JhXp_vBiJ2BK",
        "collapsed": true
      },
      "id": "JhXp_vBiJ2BK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "tQoPqKCmnM03"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tQoPqKCmnM03"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y4)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "BMBZ7AbTnM04",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "BMBZ7AbTnM04"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y4)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'AdaBoost':\n",
        "        variable_importance = clf.feature_importances_\n",
        "        print(f\"\\nVariable Importance for {name}:\")\n",
        "        for idx, importance in enumerate(variable_importance):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot variable importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, variable_importance, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        #plt.ylabel('Feature')\n",
        "        #plt.title('Variable Importance for Random Forest Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        '''for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(variable_importance[idx], 2),\n",
        "                     va='center', ha='left')'''\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "NzdUV2Lkc6H_",
        "collapsed": true
      },
      "id": "NzdUV2Lkc6H_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "1auBT4FtnM04"
      },
      "id": "1auBT4FtnM04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "zfx1gsmPJ49i"
      },
      "id": "zfx1gsmPJ49i"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler  # Import SMOTE and RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with SMOTE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply SMOTE to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply SMOTE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "15Pu37elJ9bj",
        "collapsed": true
      },
      "id": "15Pu37elJ9bj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.inspection import permutation_importance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to check and handle negative values\n",
        "def preprocess_data(X):\n",
        "    # Check for negative values\n",
        "    if (X < 0).any().any():\n",
        "        print(\"Warning: Negative values found. Applying Min-Max scaling.\")\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "    return X\n",
        "\n",
        "# Load or split your dataset here\n",
        "# For example:\n",
        "# X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Example data preprocessing\n",
        "# X_train_full = preprocess_data(X_train_full)\n",
        "# X_test = preprocess_data(X_test)\n",
        "\n",
        "# Define GaussianNB model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train_full = preprocess_data(X_train_full)\n",
        "X_test = preprocess_data(X_test)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Compute permutation importance\n",
        "def compute_permutation_importance(model, X_test, y_test):\n",
        "    # Compute permutation importance\n",
        "    results = permutation_importance(model, X_test, y_test, scoring='f1_weighted', n_repeats=10, random_state=42)\n",
        "    importance_scores = results.importances_mean\n",
        "\n",
        "    # Create a DataFrame to show feature importances\n",
        "    feature_names = df_filtered.columns.tolist()\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importance_scores\n",
        "    })\n",
        "\n",
        "    return importance_df\n",
        "\n",
        "# Compute and print feature importances\n",
        "importance_df = compute_permutation_importance(model, X_test, y_test)\n",
        "\n",
        "print(f\"\\nFeature Importances using Permutation Importance for GaussianNB:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Permutation Importance for GaussianNB')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wVw9dosiZnZ0",
        "collapsed": true
      },
      "id": "wVw9dosiZnZ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "jVmeDJg7nM04"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jVmeDJg7nM04"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y4)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0Cum5eEunM04",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "0Cum5eEunM04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "W_zeTtWLnM04"
      },
      "id": "W_zeTtWLnM04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "g04tQ8r7J-pZ"
      },
      "id": "g04tQ8r7J-pZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Check the class distribution in the dataset\n",
        "print(\"Original class distribution:\", Counter(y_train_full))\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Define function to compute learning curves with ADASYN\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ADASYN to the training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        if np.unique(y_train_cv).size > 1:  # Check if there is more than one class\n",
        "            try:\n",
        "                X_resampled, y_resampled = adasyn.fit_resample(X_train_cv, y_train_cv)\n",
        "                if len(y_resampled) > len(y_train_cv):  # Ensure resampling occurred\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    train_pred = model.predict(X_resampled)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "\n",
        "                    # Store metrics\n",
        "                    train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "                else:\n",
        "                    print(f\"Warning: No samples generated for fold {len(train_accuracies)+1}, using original data\")\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    train_pred = model.predict(X_train_cv)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "                    train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: {e} for fold {len(train_accuracies)+1}, using original data\")\n",
        "                model.fit(X_train_cv, y_train_cv)\n",
        "                train_pred = model.predict(X_train_cv)\n",
        "                val_pred = model.predict(X_val_cv)\n",
        "                train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "        else:\n",
        "            # If only one class is present, no resampling needed\n",
        "            model.fit(X_train_cv, y_train_cv)\n",
        "            train_pred = model.predict(X_train_cv)\n",
        "            val_pred = model.predict(X_val_cv)\n",
        "            train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "            val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=LeaveOneOut(),\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ADASYN to the full training data and refit the best model\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                best_model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                best_model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            best_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ADASYN to the full training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "pG0_m9tpKAXK",
        "collapsed": true
      },
      "id": "pG0_m9tpKAXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y4)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=12)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=12)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ukkWaAhOnM05",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "ukkWaAhOnM05"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking DJ Contact Time Prediction**\n",
        "\n",
        "Here you can find the best combination for DJ conctact time"
      ],
      "metadata": {
        "id": "JC-k1r0QpJca"
      },
      "id": "JC-k1r0QpJca"
    },
    {
      "cell_type": "code",
      "source": [
        "bin_edges = [0, 21, 41]  # 0-20 (top 20), 21-40 (next 20)\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "reviews3 = data['Reviews_DJCont'] = pd.cut(data['Ranking_DJCont'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "A55T4OJYpJcb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "A55T4OJYpJcb"
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_DJCont']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_DJCont'] = reviews"
      ],
      "metadata": {
        "id": "59EgvD1317cV"
      },
      "id": "59EgvD1317cV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y5 = data['Reviews_DJCont']"
      ],
      "metadata": {
        "id": "DlTflCH2pJcc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DlTflCH2pJcc"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y5, test_size = 0.25, random_state=42)"
      ],
      "metadata": {
        "id": "h677qM_xpJcc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "h677qM_xpJcc"
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "MTmr8RyKpJcc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "MTmr8RyKpJcc"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y5)"
      ],
      "metadata": {
        "id": "FeI0E8rbjpp8"
      },
      "id": "FeI0E8rbjpp8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**"
      ],
      "metadata": {
        "id": "lm7YGnuWpJcc"
      },
      "id": "lm7YGnuWpJcc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "CpyDZivqKGnD"
      },
      "id": "CpyDZivqKGnD"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "DeWpKa8gKHzS",
        "collapsed": true
      },
      "id": "DeWpKa8gKHzS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "ZQJsdqLapJcd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZQJsdqLapJcd"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y5)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "F_49mWdYpJcd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "F_49mWdYpJcd"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.inspection import permutation_importance  # Added\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y5)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'SVM':\n",
        "        # Calculate permutation importance\n",
        "        result = permutation_importance(clf, x_train, y_train, scoring='accuracy', n_repeats=10, random_state=42)\n",
        "        importances = result.importances_mean\n",
        "\n",
        "        print(f\"\\nPermutation Importance for {name}:\")\n",
        "        for idx, importance in enumerate(importances):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot permutation importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, importances, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        plt.ylabel('Feature')\n",
        "        plt.title('Permutation Importance for SVM Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(importances[idx], 2),\n",
        "                     va='center', ha='left')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "Hw7QV55DeF-Q",
        "collapsed": true
      },
      "id": "Hw7QV55DeF-Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "8BqD2k_upJcd"
      },
      "id": "8BqD2k_upJcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "T3fwEhMnKJIV"
      },
      "id": "T3fwEhMnKJIV"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with SMOTE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply SMOTE to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply SMOTE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NWGUjqN2KKcm",
        "collapsed": true
      },
      "id": "NWGUjqN2KKcm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.inspection import permutation_importance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to check and handle negative values\n",
        "def preprocess_data(X):\n",
        "    # Check for negative values\n",
        "    if (X < 0).any().any():\n",
        "        print(\"Warning: Negative values found. Applying Min-Max scaling.\")\n",
        "        scaler = MinMaxScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "    return X\n",
        "\n",
        "# Load or split your dataset here\n",
        "# For example:\n",
        "# X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Example data preprocessing\n",
        "X_train_full = preprocess_data(X_train_full)\n",
        "X_test = preprocess_data(X_test)\n",
        "\n",
        "# Define SVM model\n",
        "model = SVC(probability=True, kernel='rbf', random_state=42)  # SVM with probability=True for better handling\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_full, y_train_full)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Compute permutation importance\n",
        "def compute_permutation_importance(model, X_test, y_test):\n",
        "    # Compute permutation importance\n",
        "    results = permutation_importance(model, X_test, y_test, scoring='f1_weighted', n_repeats=10, random_state=42)\n",
        "    importance_scores = results.importances_mean\n",
        "\n",
        "    # Create a DataFrame to show feature importances\n",
        "    feature_names = df_filtered.columns.tolist()\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importance_scores\n",
        "    })\n",
        "\n",
        "    return importance_df\n",
        "\n",
        "# Compute and print feature importances\n",
        "importance_df = compute_permutation_importance(model, X_test, y_test)\n",
        "\n",
        "print(f\"\\nFeature Importances using Permutation Importance for SVM:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Permutation Importance for SVM')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "txG_f0hloIn1",
        "collapsed": true
      },
      "id": "txG_f0hloIn1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "sHZ0-FfZpJcd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "sHZ0-FfZpJcd"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y5)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "O28SP_E4pJce",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "O28SP_E4pJce"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "gzGPrqQ1pJce"
      },
      "id": "gzGPrqQ1pJce"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "QCKj1J3BKNxt"
      },
      "id": "QCKj1J3BKNxt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Check the class distribution in the dataset\n",
        "print(\"Original class distribution:\", Counter(y_train_full))\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Define function to compute learning curves with ADASYN\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ADASYN to the training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        if np.unique(y_train_cv).size > 1:  # Check if there is more than one class\n",
        "            try:\n",
        "                X_resampled, y_resampled = adasyn.fit_resample(X_train_cv, y_train_cv)\n",
        "                if len(y_resampled) > len(y_train_cv):  # Ensure resampling occurred\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    train_pred = model.predict(X_resampled)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "\n",
        "                    # Store metrics\n",
        "                    train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "                else:\n",
        "                    print(f\"Warning: No samples generated for fold {len(train_accuracies)+1}, using original data\")\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    train_pred = model.predict(X_train_cv)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "                    train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: {e} for fold {len(train_accuracies)+1}, using original data\")\n",
        "                model.fit(X_train_cv, y_train_cv)\n",
        "                train_pred = model.predict(X_train_cv)\n",
        "                val_pred = model.predict(X_val_cv)\n",
        "                train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "        else:\n",
        "            # If only one class is present, no resampling needed\n",
        "            model.fit(X_train_cv, y_train_cv)\n",
        "            train_pred = model.predict(X_train_cv)\n",
        "            val_pred = model.predict(X_val_cv)\n",
        "            train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "            val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=LeaveOneOut(),\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ADASYN to the full training data and refit the best model\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                best_model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                best_model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            best_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ADASYN to the full training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "wXKkcRrCKO8I",
        "collapsed": true
      },
      "id": "wXKkcRrCKO8I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y5)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=4)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=4)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gAeGx8aSpJcf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "gAeGx8aSpJcf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ranking RSI Prediction**\n",
        "\n",
        "Here you can find the best combination for RSI."
      ],
      "metadata": {
        "id": "iNLXYLsht1W2"
      },
      "id": "iNLXYLsht1W2"
    },
    {
      "cell_type": "code",
      "source": [
        "bin_edges = [0, 21, 41]  # 0-20 (top 20), 21-40 (next 20)\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['top_20', 'next_20']\n",
        "\n",
        "reviews3 = data['Reviews_RSI'] = pd.cut(data['Ranking_RSI'], bins=bin_edges, labels=bin_labels, include_lowest=True)"
      ],
      "metadata": {
        "id": "_fKQQ97gt1W3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_fKQQ97gt1W3"
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "for i in data['Ranking_RSI']:\n",
        "    if i >= 1 and i <= 21:\n",
        "        reviews.append('0')\n",
        "    elif i >= 22 and i <= 41:\n",
        "        reviews.append('1')\n",
        "\n",
        "data['Reviews_RSI'] = reviews"
      ],
      "metadata": {
        "id": "PmVXwHoj_zMB"
      },
      "id": "PmVXwHoj_zMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y6 = data['Reviews_RSI']"
      ],
      "metadata": {
        "id": "63P1ppjxt1W3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "63P1ppjxt1W3"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y6, test_size = 0.25, random_state=42)"
      ],
      "metadata": {
        "id": "1u0Zy-jmt1W4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1u0Zy-jmt1W4"
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "cKaZUcWIt1W4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "cKaZUcWIt1W4"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y6)"
      ],
      "metadata": {
        "id": "fMORNIe1jsLa"
      },
      "id": "fMORNIe1jsLa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rose Balancing Method**"
      ],
      "metadata": {
        "id": "Ib0R8iMgt1W5"
      },
      "id": "Ib0R8iMgt1W5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "q786SBBcKUAy"
      },
      "id": "q786SBBcKUAy"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with ROSE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ROSE to the training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ROSE to the full training data and refit the best model\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ROSE to the full training data\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = ros.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7VLfTUV-Kik3",
        "collapsed": true
      },
      "id": "7VLfTUV-Kik3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "6S29MjlWt1W5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6S29MjlWt1W5"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y6)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "ogdVT0rat1W5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "ogdVT0rat1W5"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y6)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "    # Get variable importance for Random Forest and create a plot\n",
        "    if name == 'XGBoost':\n",
        "        variable_importance = clf.feature_importances_\n",
        "        print(f\"\\nVariable Importance for {name}:\")\n",
        "        for idx, importance in enumerate(variable_importance):\n",
        "            print(f\"Feature {idx}: {importance}\")\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = df_filtered.columns.tolist()  # Assuming X_projected is a DataFrame with column names\n",
        "\n",
        "        # Plot variable importances with feature names\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.barh(feature_names, variable_importance, color='skyblue')\n",
        "        plt.xlabel('Importance')\n",
        "        #plt.ylabel('Feature')\n",
        "        #plt.title('Variable Importance for Random Forest Classifier')\n",
        "\n",
        "        # Add text annotations\n",
        "        '''for idx, bar in enumerate(bars):\n",
        "            plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, round(variable_importance[idx], 2),\n",
        "                     va='center', ha='left')'''\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.axes_style(\"whitegrid\")\n",
        "        sns.despine(left=True, bottom=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "wJOe-pKIgiqV",
        "collapsed": true
      },
      "id": "wJOe-pKIgiqV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SMOTE Balancing Method**"
      ],
      "metadata": {
        "id": "xzD0XP5vt1W6"
      },
      "id": "xzD0XP5vt1W6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "eIZXqnx0KaYp"
      },
      "id": "eIZXqnx0KaYp"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Initialize Leave-One-Out Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Define function to compute learning curves with SMOTE\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply SMOTE to the training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        train_pred = model.predict(X_resampled)\n",
        "        val_pred = model.predict(X_val_cv)\n",
        "\n",
        "        # Store metrics\n",
        "        train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "        val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=loo,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply SMOTE to the full training data and refit the best model\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        best_model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply SMOTE to the full training data\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled_full, y_resampled_full = smote.fit_resample(X_train_full, y_train_full)\n",
        "        model.fit(X_resampled_full, y_resampled_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T8mr1uDlKhmo",
        "collapsed": true
      },
      "id": "T8mr1uDlKhmo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming best_model is the best AdaBoost model obtained from GridSearchCV\n",
        "# and X_resampled_full is the resampled training data used for fitting best_model\n",
        "\n",
        "# Define a function to get model predictions\n",
        "def predict_fn(X):\n",
        "    return best_model.predict_proba(X)\n",
        "\n",
        "# Initialize SHAP Explainer\n",
        "explainer = shap.KernelExplainer(predict_fn, X_resampled_full)\n",
        "\n",
        "# Compute SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Print the shape of SHAP values for debugging\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "# Check if SHAP values are a list (binary classification scenario)\n",
        "if isinstance(shap_values, list):\n",
        "    # Extract SHAP values for the positive class (usually the second class)\n",
        "    shap_values_class = shap_values[1]\n",
        "else:\n",
        "    # If not a list, assume it's already for the positive class\n",
        "    shap_values_class = shap_values\n",
        "\n",
        "# Ensure SHAP values are 2D with shape (num_samples, num_features)\n",
        "if shap_values_class.ndim == 3:\n",
        "    # If 3D, handle the case appropriately\n",
        "    shap_values_class = shap_values_class[:, :, 1]  # Select the SHAP values for the positive class if 3D\n",
        "elif shap_values_class.ndim != 2:\n",
        "    raise ValueError(f\"Unexpected SHAP values shape: {shap_values_class.shape}\")\n",
        "\n",
        "# Calculate mean absolute SHAP values for feature importance\n",
        "mean_shap_values = np.mean(np.abs(shap_values_class), axis=0)\n",
        "\n",
        "# Get feature names directly from the DataFrame\n",
        "feature_names = df_filtered.columns.tolist()\n",
        "\n",
        "# Ensure lengths match\n",
        "if len(feature_names) != len(mean_shap_values):\n",
        "    print(f\"Length mismatch: feature_names ({len(feature_names)}) != mean_shap_values ({len(mean_shap_values)})\")\n",
        "    # Optionally handle the mismatch here\n",
        "\n",
        "# Ensure 1D arrays\n",
        "feature_names = np.array(feature_names).flatten()\n",
        "mean_shap_values = np.array(mean_shap_values).flatten()\n",
        "\n",
        "# Create a DataFrame to show feature importances\n",
        "try:\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': mean_shap_values\n",
        "    })\n",
        "    # Print feature importances\n",
        "    print(\"\\nFeature Importances using SHAP for Best AdaBoost Model:\")\n",
        "    print(importance_df)\n",
        "except ValueError as e:\n",
        "    print(f\"Error creating DataFrame: {e}\")\n",
        "\n",
        "# Plot SHAP summary plot\n",
        "shap.summary_plot(shap_values_class, X_test)\n"
      ],
      "metadata": {
        "id": "gGM3C9wQ7o5A",
        "collapsed": true
      },
      "id": "gGM3C9wQ7o5A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a function to get model predictions\n",
        "def predict_fn(X, model):\n",
        "    return model.predict_proba(X)\n",
        "\n",
        "# Initialize LOO Cross-Validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize list to collect SHAP values for each fold\n",
        "all_shap_values = []\n",
        "\n",
        "# Loop through each train-test split\n",
        "for train_index, test_index in loo.split(X_resampled_full):\n",
        "    # Split data\n",
        "    X_train, X_test_fold = X_resampled_full[train_index], X_resampled_full[test_index]\n",
        "    y_train, y_test_fold = y_resampled_full[train_index], y_resampled_full[test_index]\n",
        "\n",
        "    # Train the model on the training set\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    # Initialize SHAP Explainer for the current fold\n",
        "    explainer = shap.KernelExplainer(lambda x: predict_fn(x, best_model), X_train)\n",
        "\n",
        "    # Compute SHAP values for the test set in the current fold\n",
        "    shap_values_fold = explainer.shap_values(X_test_fold)\n",
        "\n",
        "    # Check if SHAP values are a list (binary classification scenario)\n",
        "    if isinstance(shap_values_fold, list):\n",
        "        # Extract SHAP values for the positive class (usually the second class)\n",
        "        shap_values_fold_class = shap_values_fold[1]\n",
        "    else:\n",
        "        # If not a list, assume it's already for the positive class\n",
        "        shap_values_fold_class = shap_values_fold\n",
        "\n",
        "    # Ensure SHAP values are 2D with shape (num_samples, num_features)\n",
        "    if shap_values_fold_class.ndim == 3:\n",
        "        # If 3D, handle the case appropriately\n",
        "        shap_values_fold_class = shap_values_fold_class[:, :, 1]  # Select the SHAP values for the positive class if 3D\n",
        "    elif shap_values_fold_class.ndim != 2:\n",
        "        raise ValueError(f\"Unexpected SHAP values shape: {shap_values_fold_class.shape}\")\n",
        "\n",
        "    # Append SHAP values for the current fold\n",
        "    all_shap_values.append(shap_values_fold_class)\n",
        "\n",
        "# Concatenate all SHAP values across folds\n",
        "all_shap_values = np.vstack(all_shap_values)\n",
        "\n",
        "# Calculate mean absolute SHAP values for feature importance\n",
        "mean_shap_values = np.mean(np.abs(all_shap_values), axis=0)\n",
        "\n",
        "# Get feature names directly from the DataFrame\n",
        "feature_names = df_filtered.columns.tolist()\n",
        "\n",
        "# Ensure lengths match\n",
        "if len(feature_names) != len(mean_shap_values):\n",
        "    print(f\"Length mismatch: feature_names ({len(feature_names)}) != mean_shap_values ({len(mean_shap_values)})\")\n",
        "    # Optionally handle the mismatch here\n",
        "\n",
        "# Ensure 1D arrays\n",
        "feature_names = np.array(feature_names).flatten()\n",
        "mean_shap_values = np.array(mean_shap_values).flatten()\n",
        "\n",
        "# Create a DataFrame to show feature importances\n",
        "try:\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': mean_shap_values\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Print feature importances\n",
        "    print(\"\\nFeature Importances using SHAP for Best AdaBoost Model:\")\n",
        "    print(importance_df)\n",
        "except ValueError as e:\n",
        "    print(f\"Error creating DataFrame: {e}\")\n",
        "\n",
        "# Plot SHAP summary plot for the entire dataset (combine all data used)\n",
        "explainer_full = shap.KernelExplainer(lambda x: predict_fn(x, best_model), X_resampled_full)\n",
        "shap_values_full = explainer_full.shap_values(X_resampled_full)\n",
        "\n",
        "# Check if SHAP values are a list (binary classification scenario)\n",
        "if isinstance(shap_values_full, list):\n",
        "    # Extract SHAP values for the positive class (usually the second class)\n",
        "    shap_values_class_full = shap_values_full[1]\n",
        "else:\n",
        "    # If not a list, assume it's already for the positive class\n",
        "    shap_values_class_full = shap_values_full\n",
        "\n",
        "# Plot SHAP summary plot\n",
        "shap.summary_plot(shap_values_class_full, X_resampled_full)\n"
      ],
      "metadata": {
        "id": "TyNLva0kd0D6",
        "collapsed": true
      },
      "id": "TyNLva0kd0D6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN, SMOTE"
      ],
      "metadata": {
        "id": "YqpF2t0Pt1W6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YqpF2t0Pt1W6"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y6)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost':xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqWpDmqwt1W7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZqWpDmqwt1W7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADASYN Balacing Method**"
      ],
      "metadata": {
        "id": "Pau5cKL1t1W8"
      },
      "id": "Pau5cKL1t1W8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave-One-Out"
      ],
      "metadata": {
        "id": "AlcOq2xnKejm"
      },
      "id": "AlcOq2xnKejm"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Check the class distribution in the dataset\n",
        "print(\"Original class distribution:\", Counter(y_train_full))\n",
        "\n",
        "# Define parameter grids for each classifier\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Naive Bayes': {},\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 6, 10],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier()\n",
        "}\n",
        "\n",
        "# Define function to compute learning curves with ADASYN\n",
        "def compute_learning_curves(model, X, y):\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "\n",
        "    for train_index, val_index in loo.split(X):\n",
        "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
        "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
        "\n",
        "        # Apply ADASYN to the training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        if np.unique(y_train_cv).size > 1:  # Check if there is more than one class\n",
        "            try:\n",
        "                X_resampled, y_resampled = adasyn.fit_resample(X_train_cv, y_train_cv)\n",
        "                if len(y_resampled) > len(y_train_cv):  # Ensure resampling occurred\n",
        "                    model.fit(X_resampled, y_resampled)\n",
        "                    train_pred = model.predict(X_resampled)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "\n",
        "                    # Store metrics\n",
        "                    train_accuracies.append(accuracy_score(y_resampled, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "                else:\n",
        "                    print(f\"Warning: No samples generated for fold {len(train_accuracies)+1}, using original data\")\n",
        "                    model.fit(X_train_cv, y_train_cv)\n",
        "                    train_pred = model.predict(X_train_cv)\n",
        "                    val_pred = model.predict(X_val_cv)\n",
        "                    train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                    val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: {e} for fold {len(train_accuracies)+1}, using original data\")\n",
        "                model.fit(X_train_cv, y_train_cv)\n",
        "                train_pred = model.predict(X_train_cv)\n",
        "                val_pred = model.predict(X_val_cv)\n",
        "                train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "                val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "        else:\n",
        "            # If only one class is present, no resampling needed\n",
        "            model.fit(X_train_cv, y_train_cv)\n",
        "            train_pred = model.predict(X_train_cv)\n",
        "            val_pred = model.predict(X_val_cv)\n",
        "            train_accuracies.append(accuracy_score(y_train_cv, train_pred))\n",
        "            val_accuracies.append(accuracy_score(y_val_cv, val_pred))\n",
        "\n",
        "    return train_accuracies, val_accuracies\n",
        "\n",
        "# Perform Grid Search with LOOCV\n",
        "for name, model in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        # Configure GridSearchCV\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring='f1_weighted',\n",
        "            cv=LeaveOneOut(),\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        # Fit GridSearchCV with LOOCV\n",
        "        grid_search.fit(X_train_full, y_train_full)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best F1 Score: {grid_search.best_score_}\")\n",
        "\n",
        "        # Retrieve the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Apply ADASYN to the full training data and refit the best model\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                best_model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                best_model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            best_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(best_model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # For classifiers without hyperparameter tuning\n",
        "        # Apply ADASYN to the full training data\n",
        "        adasyn = ADASYN(random_state=42, sampling_strategy='auto')  # Set sampling_strategy to 'auto'\n",
        "        try:\n",
        "            X_resampled_full, y_resampled_full = adasyn.fit_resample(X_train_full, y_train_full)\n",
        "            if len(y_resampled_full) > len(y_train_full):  # Ensure resampling occurred\n",
        "                model.fit(X_resampled_full, y_resampled_full)\n",
        "            else:\n",
        "                print(f\"Warning: No samples generated, using original data\")\n",
        "                model.fit(X_train_full, y_train_full)\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: {e}, using original data\")\n",
        "            model.fit(X_train_full, y_train_full)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        acc_test = accuracy_score(y_test, y_test_pred)\n",
        "        precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
        "        recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "        f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "        conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"\\nClassifier: {name}\")\n",
        "        print(f\"Test Accuracy: {acc_test}\")\n",
        "        print(f\"Test Precision: {precision_test}\")\n",
        "        print(f\"Test Recall: {recall_test}\")\n",
        "        print(f\"Test F1-score: {f1_test}\")\n",
        "        print(f\"Test Confusion Matrix:\\n{conf_matrix_test}\")\n",
        "\n",
        "        # Compute learning curves\n",
        "        train_accuracies, val_accuracies = compute_learning_curves(model, X_train_full, y_train_full)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_accuracies, label='Training Accuracy')\n",
        "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "        plt.xlabel('Leave-One-Out Fold')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Learning Curves for {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "QlyU4PzTKgAG",
        "collapsed": true
      },
      "id": "QlyU4PzTKgAG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y6)\n",
        "\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_projected, y_encoded, test_size=0.25, random_state=4)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = GaussianNB()\n",
        "svm = SVC()\n",
        "ada = AdaBoostClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Apply ADASYN to training data\n",
        "adasyn = ADASYN(random_state=4)\n",
        "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "classifiers = {'Random Forest': rf, 'Naive Bayes': nb, 'SVM': svm, 'AdaBoost': ada, 'XGBoost': xgb}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_resampled, y_resampled)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nClassifier: {name}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EbHNkMKEt1W9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "EbHNkMKEt1W9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing SVM and Nayve Bayes Permutation Importance"
      ],
      "metadata": {
        "id": "eJtlMUo-qzIH"
      },
      "id": "eJtlMUo-qzIH"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define feature names\n",
        "feature_names = [\n",
        "    'Weight (kg)', '%Body Fat', '1RM Hip Thrust (kg)', '1RM Back Squat (kg)',\n",
        "    'Relative 1RM HT(kg)', 'Relative 1RM Squat (kg)', 'Speed 5m (s)',\n",
        "    'Speed 20m (s)', 'v02 Max (ml.kg-1.min-1)', 'Baseline Drop Jump (cm)',\n",
        "    'Baseline Contact time (s)', 'Baseline RSI', 'Baseline CMJ (cm)'\n",
        "]\n",
        "\n",
        "# Define the data\n",
        "data3 = {\n",
        "    'PR\\n(ROSE and \\nAdaBoost)': [\n",
        "        0.000, 0.000, 0.056, 0.308, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.075, 0.000, 0.000\n",
        "    ],\n",
        "    'CK\\n(ADASYN and \\nRandom Forrest)': [\n",
        "        0.331, 0.479, 0.158, 0.688, 0.790, 0.809, 0.391, 0.451, 0.925, 0.493, 0.412, 0.193, 0.000\n",
        "    ],\n",
        "    'CMJ\\n(ADASYN and \\nXGBoost)': [\n",
        "        0.040, 0.061, 0.523, 0.095, 0.204, 0.218, 0.048, 0.191, 0.169, 0.810, 0.532, 0.066, 0.011\n",
        "    ],\n",
        "    'RSI\\n(SMOTE and \\nAdaBoost)': [\n",
        "        0,\n",
        "0.002,\n",
        "0,\n",
        "0,\n",
        "0,\n",
        "0.013,\n",
        "0.001,\n",
        "0.025,\n",
        "0.071,\n",
        "0.004,\n",
        "0,\n",
        "0.018,\n",
        "0]\n",
        "}\n",
        "\n",
        "palette = sns.light_palette(\"seagreen\", 16)\n",
        "\n",
        "# Create DataFrame\n",
        "df_filtered2 = pd.DataFrame(data3, index=feature_names)\n",
        "\n",
        "# Create the heatmap with a color map that handles both positive and negative values\n",
        "plt.figure(figsize=(14, 8))\n",
        "ax = sns.heatmap(df_filtered2.T, annot=True, cmap=palette,\n",
        "                 annot_kws={\"size\": 13}, center=0, cbar_kws={\"shrink\": .8, \"aspect\": 10, \"pad\": 0.05})\n",
        "\n",
        "# Set y-axis labels and title\n",
        "ax.set_yticklabels(df_filtered2.columns, rotation=0,ha='center', fontsize=14)\n",
        "ax.tick_params(axis='y', labelsize=11, pad=45)\n",
        "ax.tick_params(axis='x', labelsize=11)\n",
        "ax.set_xticklabels(df_filtered2.index,  ha='center', fontsize=13)  # Manually set xticklabels\n",
        "\n",
        "# Add title\n",
        "#plt.title('Feature Importances for Different Models and Variables', size=20)\n",
        "\n",
        "# Adjust layout to fit labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save and show the plot\n",
        "plt.savefig('feature_importances.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fquIODhjy7cK",
        "collapsed": true
      },
      "id": "fquIODhjy7cK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM and Nayve Bayes Permutation Importance"
      ],
      "metadata": {
        "id": "1VkFwG5GY_jk"
      },
      "id": "1VkFwG5GY_jk"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming data3 is your feature importance dictionary\n",
        "data3 = {\n",
        "    'PR\\n(ROSE and \\nAdaBoost)': [0.000, 0.000, 0.056, 0.308, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.075, 0.000, 0.000],\n",
        "    'CK\\n(ADASYN and \\nRandom Forrest)': [0.331, 0.479, 0.158, 0.688, 0.790, 0.809, 0.391, 0.451, 0.925, 0.493, 0.412, 0.193, 0.000],\n",
        "    'CMJ\\n(ADASYN and \\nXGBoost)': [0.040, 0.061, 0.523, 0.095, 0.204, 0.218, 0.048, 0.191, 0.169, 0.810, 0.532, 0.066, 0.011],\n",
        "    'DJ\\n(SMOTE and GB Naive Bayes)': [0.000, 0.003, -0.145, -0.147, -0.098, 0.027, 0.000, 0.000, -0.080, 0.065, -0.134, -0.094, -0.151],\n",
        "    'DJCT\\n(SMOTE and SVM)': [0.025, 0.028, 0.065, 0.075, 0.082, -0.048, -0.177, 0.082, 0.082, 0.018, 0.025, 0.076, 0.011],\n",
        "    'RSI\\n(SMOTE and \\nAdaBoost)': [0, 0.002, 0, 0, 0, 0.013, 0.001, 0.025, 0.071, 0.004, 0, 0.018, 0]\n",
        "}\n",
        "\n",
        "# Define feature names\n",
        "feature_names = [\n",
        "    'Weight (kg)', '%Body Fat', '1RM Hip Thrust (kg)', '1RM Back Squat (kg)',\n",
        "    'Relative 1RM HT(kg)', 'Relative 1RM Squat (kg)', 'Speed 5m (s)',\n",
        "    'Speed 20m (s)', 'v02 Max (ml.kg-1.min-1)', 'Baseline Drop Jump (cm)',\n",
        "    'Baseline Contact time (s)', 'Baseline RSI', 'Baseline CMJ (cm)'\n",
        "]\n",
        "\n",
        "# Create DataFrame for SVM and Naive Bayes\n",
        "svm_nb_data = {\n",
        "    'DJ\\n(SMOTE and GB Naive Bayes)': data3['DJ\\n(SMOTE and GB Naive Bayes)'],\n",
        "    'DJCT\\n(SMOTE and SVM)': data3['DJCT\\n(SMOTE and SVM)']\n",
        "}\n",
        "\n",
        "df_svm_nb = pd.DataFrame(svm_nb_data, index=feature_names)\n",
        "\n",
        "# Convert DataFrame to long format for easier plotting\n",
        "df_long = df_svm_nb.melt(var_name='Model', value_name='Decrease in Accuracy', ignore_index=False)\n",
        "df_long.reset_index(inplace=True)\n",
        "df_long.rename(columns={'index': 'Feature'}, inplace=True)\n",
        "\n",
        "# Set the seaborn style to a minimalistic theme\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Define colors\n",
        "color_naive_bayes = '#8de5a1'  # Light green\n",
        "color_svm = '#a1c9f4'          # Light blue\n",
        "\n",
        "# Create a function to plot individual models\n",
        "def plot_model(df, model_name, color, filename):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    ax = sns.barplot(x='Decrease in Accuracy', y='Feature', data=df[df['Model'] == model_name], color=color)\n",
        "    ax.set_title(f'{model_name}', fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Decrease in Accuracy Score')\n",
        "    ax.set_ylabel('', fontsize=14)\n",
        "\n",
        "    # Add value annotations on bars\n",
        "    for p in ax.patches:\n",
        "        width = p.get_width()\n",
        "        ax.annotate(f'{width:.3f}', (width, p.get_y() + p.get_height() / 2),\n",
        "                    xytext=(5, 0), textcoords='offset points',\n",
        "                    ha='left', va='center', fontsize=12, color='black')\n",
        "\n",
        "    # Remove box and x-axis\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='x', which='both', length=0)\n",
        "    ax.tick_params(axis='y', which='both', length=0)\n",
        "    ax.tick_params(axis='y', labelsize=12)  # Increase y-axis label size\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Plot for Naive Bayes\n",
        "plot_model(df_long, 'DJ\\n(SMOTE and GB Naive Bayes)', color_naive_bayes, 'naive_bayes_feature_importance.png')\n",
        "\n",
        "# Plot for SVM\n",
        "plot_model(df_long, 'DJCT\\n(SMOTE and SVM)', color_svm, 'svm_feature_importance.png')\n"
      ],
      "metadata": {
        "id": "Mx9W-ogiELVM",
        "collapsed": true
      },
      "id": "Mx9W-ogiELVM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o86VFyzXVghs"
      },
      "id": "o86VFyzXVghs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}